{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install BERT for tf2 module\n",
    "!pip install bert-for-tf2\n",
    "# Install Keras version 2.3.1\n",
    "!pip install keras==2.3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q kaggle\n",
    "from google.colab import files\n",
    "files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "! chmod 600 ~/.kaggle/kaggle.json\n",
    "!kaggle datasets download -d gianmarco96/upmcfood101\n",
    "!unzip upmcfood101.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    %tensorflow_version 2.x\n",
    "except Exception:\n",
    "    pass\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator \n",
    "from tensorflow.keras import applications\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.regularizers import l2, l1\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import bert\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import re\n",
    "import glob\n",
    "import os\n",
    "import cv2\n",
    "import sys\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=['image_path', 'text', 'food']\n",
    "train = pd.read_csv('train_titles.csv', names=columns, header=None, sep = ',', index_col=['image_path'])\n",
    "test = pd.read_csv('test_titles.csv', names=columns, header=None, sep = ',', index_col=['image_path'])\n",
    "\n",
    "# Sort values by 'image_path'\n",
    "test = test.sort_values('image_path')\n",
    "train = train.sort_values('image_path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_missing(file, df):\n",
    "  parts = file.split(os.sep)\n",
    "  idx = parts[-1]\n",
    "  cls = parts[-2]\n",
    "  indexes = df[:,0]\n",
    "  classes = df[:,2]\n",
    "\n",
    "  if idx in indexes:\n",
    "    text = df[idx == indexes][0,1]\n",
    "    return pd.NA, pd.NA, pd.NA\n",
    "  else:\n",
    "    text = df[cls == classes][0,1]\n",
    "    \n",
    "  return idx, text, cls   \n",
    "\n",
    "vec_get_missing = np.vectorize(get_missing, signature='(),(m,n)->(),(),()')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for images loading\n",
    "\n",
    "def add_not_found(path, df):\n",
    "  files = glob.glob(path)\n",
    "  df = df.reset_index()\n",
    "  idxs, texts, cls = vec_get_missing(files, df.values)\n",
    "  \n",
    "  found = pd.DataFrame({\"text\": texts,\n",
    "                        \"food\": cls,\n",
    "                       \"image_path\": idxs})\n",
    "  na = found.isna().sum().values[0]\n",
    "  if na<found.shape[0]:\n",
    "    df = df.append(found)\n",
    "  df = df.drop_duplicates(subset='image_path', keep='first').dropna()\n",
    "  df = df.set_index('image_path')\n",
    "  df = shuffle(df, random_state = 0)\n",
    "  return df      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Images folders \n",
    "train = add_not_found('/content/images/train/*/*.jpg', train)\n",
    "test = add_not_found('/content/images/test/*/*.jpg', test)\n",
    "\n",
    "print(\"Number of training images:\",train.shape[0])\n",
    "print(\"Number of test images:\",test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the BERT BASE model from Tensorflow HUB (layer, vocab_file and tokenizer)\n",
    "BertTokenizer = bert.bert_tokenization.FullTokenizer\n",
    "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\",\n",
    "                            trainable=False)\n",
    "vocabulary_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
    "to_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
    "tokenizer = BertTokenizer(vocabulary_file, to_lower_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing of texts according to BERT +\n",
    "# Cleaning of the texts\n",
    "\n",
    "def preprocess_text(sen):\n",
    "    # Removing html tags\n",
    "    sentence = remove_tags(sen)\n",
    "    # Remove punctuations and numbers\n",
    "    sentence = re.sub('[^a-zA-Z]', ' ', sentence)\n",
    "    # Single character removal\n",
    "    sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)\n",
    "    # Removing multiple spaces\n",
    "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
    "    sentence = sentence.lower()\n",
    "    return sentence\n",
    "\n",
    "def remove_tags(text):\n",
    "    return TAG_RE.sub('', text)\n",
    "\n",
    "TAG_RE = re.compile(r'<[^>]+>')\n",
    "vec_preprocess_text = np.vectorize(preprocess_text)\n",
    "\n",
    "def get_tokens(text, tokenizer):\n",
    "  tokens = tokenizer.tokenize(text)\n",
    "  tokens = [\"[CLS]\"] + tokens + [\"[SEP]\"]\n",
    "  length = len(tokens)\n",
    "  if length > max_length:\n",
    "      tokens = tokens[:max_length]\n",
    "  return tokens, length  \n",
    "\n",
    "def get_masks(text, tokenizer, max_length):\n",
    "    \"\"\"Mask for padding\"\"\"\n",
    "    tokens, length = get_tokens(text, tokenizer)\n",
    "    return np.asarray([1]*len(tokens) + [0] * (max_length - len(tokens)))\n",
    "vec_get_masks = np.vectorize(get_masks, signature = '(),(),()->(n)')\n",
    "\n",
    "def get_segments(text, tokenizer, max_length):\n",
    "    \"\"\"Segments: 0 for the first sequence, 1 for the second\"\"\"\n",
    "    tokens, length = get_tokens(text, tokenizer)\n",
    "    segments = []\n",
    "    current_segment_id = 0\n",
    "    for token in tokens:\n",
    "        segments.append(current_segment_id)\n",
    "        if token == \"[SEP]\":\n",
    "            current_segment_id = 1\n",
    "    return np.asarray(segments + [0] * (max_length - len(tokens)))\n",
    "vec_get_segments = np.vectorize(get_segments, signature = '(),(),()->(n)')\n",
    "\n",
    "def get_ids(text, tokenizer, max_length):\n",
    "    \"\"\"Token ids from Tokenizer vocab\"\"\"\n",
    "    tokens, length = get_tokens(text, tokenizer)\n",
    "    token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "    input_ids = np.asarray(token_ids + [0] * (max_length-length))\n",
    "    return input_ids\n",
    "vec_get_ids = np.vectorize(get_ids, signature = '(),(),()->(n)')\n",
    "\n",
    "def get_texts(path):\n",
    "    path = path.decode('utf-8')\n",
    "    parts = path.split(os.sep)\n",
    "    image_name = parts[-1]\n",
    "    is_train = parts[-3] == 'train'\n",
    "    if is_train:\n",
    "      df = train\n",
    "    else:\n",
    "      df = test\n",
    "\n",
    "    text = df['text'][image_name]\n",
    "    return text\n",
    "vec_get_text = np.vectorize(get_texts)\n",
    "def prepare_text(paths):\n",
    "    #Preparing texts\n",
    "    \n",
    "    texts = vec_get_text(paths)\n",
    "    \n",
    "    text_array = vec_preprocess_text(texts)\n",
    "    ids = vec_get_ids(text_array, \n",
    "                      tokenizer, \n",
    "                      max_length).squeeze().astype(np.int32)\n",
    "    masks = vec_get_masks(text_array,\n",
    "                          tokenizer,\n",
    "                          max_length).squeeze().astype(np.int32)\n",
    "    segments = vec_get_segments(text_array,\n",
    "                                tokenizer,\n",
    "                                max_length).squeeze().astype(np.int32)\n",
    "    \n",
    "    return ids, segments, masks\n",
    "\n",
    "def clean(i, tokens):\n",
    "  try:\n",
    "    this_token = tokens[i]\n",
    "    next_token = tokens[i+1]\n",
    "  except:\n",
    "    return tokens\n",
    "  if '##' in next_token:\n",
    "      tokens.remove(next_token)\n",
    "      tokens[i] = this_token + next_token[2:]\n",
    "      tokens = clean(i, tokens)\n",
    "      return tokens\n",
    "  else:\n",
    "    i = i+1\n",
    "    tokens = clean(i, tokens)\n",
    "    return tokens\n",
    "\n",
    "def clean_text(array):\n",
    "  array = array[(array!=0) & (array != 101) & (array != 102)]\n",
    "  tokens = tokenizer.convert_ids_to_tokens(array)\n",
    "  tokens = clean(0, tokens)\n",
    "  text = ' '.join(tokens)\n",
    "  return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Images preprocessing\n",
    "def load_image(path):\n",
    "    path = path.decode('utf-8')\n",
    "    image = cv2.imread(path)\n",
    "    image = cv2.resize(image, (img_width, img_height))\n",
    "    image = image/255\n",
    "    image = image.astype(np.float32)\n",
    "    parts = path.split(os.sep)\n",
    "    labels = parts[-2] == Classes \n",
    "    labels = labels.astype(np.int32)\n",
    "    \n",
    "    return image, labels\n",
    "    \n",
    "vec_load_image = np.vectorize(load_image, signature = '()->(r,c,d),(s)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset creation\n",
    "\n",
    "def prepare_data(paths):\n",
    "    #Images and labels\n",
    "    images, labels = tf.numpy_function(vec_load_image, \n",
    "                                      [paths], \n",
    "                                      [tf.float32, \n",
    "                                        tf.int32])\n",
    "    \n",
    "    \n",
    "    [ids, segments, masks, ] = tf.numpy_function(prepare_text, \n",
    "                                              [paths], \n",
    "                                              [tf.int32, \n",
    "                                               tf.int32,\n",
    "                                               tf.int32])\n",
    "    images.set_shape([None, img_width, img_height, depth])\n",
    "    labels.set_shape([None, nClasses])\n",
    "    ids.set_shape([None, max_length])\n",
    "    masks.set_shape([None, max_length])\n",
    "    segments.set_shape([None, max_length])\n",
    "    return ({\"input_word_ids\": ids, \n",
    "             \"input_mask\": masks,  \n",
    "             \"segment_ids\": segments, \n",
    "             \"image\": images},\n",
    "            {\"class\": labels})\n",
    "    \n",
    "\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters setting: images width and height, depth, number if classes, input shape\n",
    "batch_size =  80\n",
    "img_width = 299\n",
    "img_height = 299\n",
    "depth = 3\n",
    "max_length = 20 #Setup according to the text\n",
    "\n",
    "nClasses = train.food.nunique()\n",
    "Classes = train.food.unique()\n",
    "input_shape = (img_width, img_height, depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Images loading using tf.data\n",
    "def tf_data(path, batch_size):\n",
    "    paths = tf.data.Dataset.list_files(path)\n",
    "    paths = paths.batch(64)\n",
    "    dataset = paths.map(prepare_data, tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.unbatch()\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.repeat()\n",
    "    return dataset   \n",
    "data_train = tf_data('images/train/*/*.jpg', batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip, op = next(iter(data_train))\n",
    "images = ip['image'][:16]\n",
    "input_word_ids = ip['input_word_ids'][:16]\n",
    "true_labels =  op['class'][:16]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print images and related texts before classification\n",
    "i=1\n",
    "texts = [clean_text(array) for array in input_word_ids.numpy()]\n",
    "plt.figure(figsize=(30,30))\n",
    "for image, label, text in zip(images.numpy(), true_labels.numpy(), texts):\n",
    "      plt.subplot(4,4,i)\n",
    "      i+=1\n",
    "      image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "      plt.imshow(image)\n",
    "      plt.axis('off')\n",
    "      plt.title(\"Text: {}\\nCategory: {}\".format(text, Classes[label.argmax(0)]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model --> classification model\n",
    "# Images Model\n",
    "model_cnn = models.Sequential()\n",
    "model_cnn.add(InceptionV3(weights='imagenet', include_top=False, input_tensor=layers.Input(shape=(299, 299, 3))))\n",
    "model_cnn.add(layers.AveragePooling2D(pool_size=(8, 8), name='AVG_Pooling'))\n",
    "model_cnn.add(layers.Dropout(.4, name='Dropout_0.4'))\n",
    "model_cnn.add(layers.Flatten(name='Flatten'))\n",
    "model_cnn.add(layers.Dense(128, name='Dense_128'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep model layers trainable\n",
    "for layer in model_cnn.layers:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "plot_model(model_cnn, to_file='model_cnn.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bert + LSTM text model\n",
    "input_ids = layers.Input(shape=(max_length,), dtype=tf.int32, name=\"input_word_ids\")\n",
    "input_masks = layers.Input(shape=(max_length,), dtype=tf.int32, name=\"input_masks\")\n",
    "input_segments = layers.Input(shape=(max_length,), dtype=tf.int32, name=\"segment_ids\")\n",
    "_, seq_out = bert_layer([input_ids, input_masks, input_segments])\n",
    "out = layers.LSTM(128, name='LSTM')(seq_out)\n",
    "model_lstm = models.Model([input_ids, input_masks, input_segments], out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep the Bert + LSTM layers trainable\n",
    "for layer in model_lstm.layers:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lstm.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model_lstm, to_file='bert_lstm.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacking early-fusion multimodal model\n",
    "\n",
    "input_word_ids = layers.Input(shape=(max_length,), dtype=tf.int32,\n",
    "                                       name=\"input_word_ids\")\n",
    "input_mask = layers.Input(shape=(max_length,), dtype=tf.int32,\n",
    "                                   name=\"input_mask\")\n",
    "segment_ids = layers.Input(shape=(max_length,), dtype=tf.int32,\n",
    "                                    name=\"segment_ids\")\n",
    "image_input = layers.Input(shape = input_shape, dtype=tf.float32,\n",
    "                           name = \"image\")\n",
    "\n",
    "image_side = model_cnn(image_input)\n",
    "text_side = model_lstm([input_word_ids, input_mask, segment_ids])\n",
    "# Concatenate features from images and texts\n",
    "merged = layers.Concatenate()([image_side, text_side])\n",
    "merged = layers.Dense(256, activation = 'relu')(merged)\n",
    "output = layers.Dense(nClasses, activation='softmax', name = \"class\")(merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Model([input_word_ids, input_mask, segment_ids, image_input], output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "plot_model(model, to_file='multimodal.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stochastic Gradient Descent optimizer\n",
    "sgd = optimizers.SGD(learning_rate=0.0001, momentum=0.9, nesterov=False)\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=sgd, \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup callbacks, logs and early stopping condition\n",
    "checkpoint_path = \"stacking_early_fusion/weights-improvement-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
    "cp = callbacks.ModelCheckpoint(checkpoint_path, monitor='val_accuracy',save_best_only=True,verbose=1, mode='max')\n",
    "csv_logger = callbacks.CSVLogger('stacking_early_fusion/stacking_early.log')\n",
    "es = callbacks.EarlyStopping(patience = 3, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce learning rate if no improvement is observed\n",
    "reduce_lr = callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_accuracy', factor=0.1, patience=1, min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model weights\n",
    "model.load_weights('stacking_early_fusion/weights-improvement-16-0.92.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and test accuracy using Plotly library\n",
    "df = pd.read_csv('stacking_early_fusion/stacking_early.log')\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=df['epoch'], y=df['accuracy'],\n",
    "                    mode='lines',\n",
    "                    name='training'))\n",
    "\n",
    "fig.add_trace(go.Scatter(x=df['epoch'], y=df['val_accuracy'],\n",
    "                    mode='lines',\n",
    "                    name='test'))\n",
    "\n",
    "fig.update_layout(\n",
    "    font_size = 20,\n",
    "    paper_bgcolor='rgba(0,0,0,0)',\n",
    "    plot_bgcolor='rgba(0,0,0,0)',\n",
    ")\n",
    "\n",
    "fig.update_xaxes(showgrid=True, gridwidth=0.5, gridcolor='Gray')\n",
    "fig.update_yaxes(showgrid=True, gridwidth=0.5, gridcolor='Gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and test loss using Plotly library\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=df['epoch'], y=df['loss'],\n",
    "                    mode='lines',\n",
    "                    name='training'))\n",
    "\n",
    "fig.add_trace(go.Scatter(x=df['epoch'], y=df['val_loss'],\n",
    "                    mode='lines',\n",
    "                    name='test'))\n",
    "\n",
    "fig.update_layout(\n",
    "    font_size = 20,\n",
    "    paper_bgcolor='rgba(0,0,0,0)',\n",
    "    plot_bgcolor='rgba(0,0,0,0)',\n",
    ")\n",
    "\n",
    "fig.update_xaxes(showgrid=True, gridwidth=0.5, gridcolor='Gray')\n",
    "fig.update_yaxes(showgrid=True, gridwidth=0.5, gridcolor='Gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model evaluation on test set\n",
    "model.evaluate(data_test,\n",
    "               steps = test.shape[0]//batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip, op = next(iter(data_test))\n",
    "images = ip['image'][:16]\n",
    "\n",
    "input_masks = ip['input_mask'][:16]\n",
    "input_word_ids = ip['input_word_ids'][:16]\n",
    "input_segments = ip['segment_ids'][:16]\n",
    "\n",
    "true_labels =  op['class'][:16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_labels = model.predict([input_word_ids,\n",
    "                             input_masks,\n",
    "                             input_segments,\n",
    "                             images])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=1\n",
    "texts = [clean_text(array) for array in input_word_ids.numpy()[:16]]\n",
    "plt.figure(figsize=(30,30))\n",
    "for image, actual_label, label, text in zip(images.numpy()[:16], true_labels.numpy()[:16], pred_labels, texts):\n",
    "      plt.subplot(4,4,i)\n",
    "      i+=1\n",
    "      image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "      plt.imshow(image)\n",
    "      plt.axis('off')\n",
    "      plt.title(\"Text: {}\\n Actual: {}\\n Predicted: {}\".format(text, Classes[actual_label.argmax(0)], Classes[label.argmax(0)]))\n",
    "      plt.xlabel(text)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
